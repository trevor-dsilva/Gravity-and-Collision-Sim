# Gravity and collision

This engine developed using only openGL simulates gravity and collision correction I implemented. 
All physics and collision correction is done in real time 

![twocube](https://github.com/user-attachments/assets/eaaabc26-6c9a-4c4c-bd91-ba10fe550707)

Application can scale for multiple cubes


![MultiCube](https://github.com/user-attachments/assets/b08ba6f7-ead6-4ac4-80dc-ff9a116667a1)


Future work on this repo involves torque, rotational forces, and custom user input for geometry 


Further Reading about the project 

Florin Dumitrescu  
Trevor DSilva  
Jahel Stewart  

Project Report: Physics Engine Development

1.0 Project Description

The project consists of implementing a physics engine that will generate and simulate a tower of boxes that stack on top of one another. The boxes should properly simulate collision as well as respond to collisions. Additionally, we planned on being able to launch a sphere at the tower as part of collision detection and response of our implementation and also giving the user the possibility to select and move a cube in the tower to showcase how our engine would react to its displacement. Once a cube is removed, it could be placed elsewhere and react with other boxes similar to how you play a game of Jenga.

2.0 Project Milestones

2.1 Setup & Time Integration

The rendering of our physics simulation will be handled by OpenGL using a boilerplate provided by Ben Cook in his udemy course “Computer Graphics with Modern Opengl and c++”. The first step in our implementation of our physics engine was setting up how the objects will be simulated in the engine. As such, we created a physics object class that will hold all the necessary information a rigid body object will require such as position, velocity, mass, forces acting upon it, etc [3]. Once that is taken care of, we need to implement a time integration method that will be used to calculate the new positions and orientations of the simulated objects. We opted for Verlet integration due to its ease of implementation and efficiency in computation compared to explicit Euler. In our implementation, we record the position and velocity of each object in a list of vectors at the beginning of the simulation which we then use along with our Verlet integration to calculate the new positions overriding the old ones. Once we have the updated list, we iterate through the list of physics objects and set the new positions and velocities of every physics object in the simulated  space in our update function.

2.2 Collision Detection

For collision detection, we calculate both broad and narrow phase collision detection for improved performance so that we wouldn’t need to constantly perform unnecessary calculations for objects that aren’t near one another. For the broad phase, we implemented a sort and sweep algorithm using AABBs [1]. The sweep and prune algorithm performs a quick sort on the minimum value of the AABB projected on an arbitrarily chosen axis. We then use that list and iterate through the objects and check whether other objects nearby are potentially colliding. If so, we create a vector of size two which will contain the colliding pair of objects which will be inserted in another list that will contain all colliding pairs. The code will break out of the loop only if the maximum value of an AABB is greater than the minimum value of the AABB we are checking for collision since there would be no possible way for them to be colliding. The algorithm also takes into consideration the variance of each axis meaning that the next axis on which we will perform the algorithm will have the biggest cluster object overlapping.
For the narrow phase we use an augmented version of GJK that uses EPA to find and return the collision normal and penetration depth between two colliding objects [7]. GJK in this case is primarily used to confirm if there is a collision between two objects by constructing a simplex from their Minkowski difference. This simplex will then be used by EPA to calculate the closest face to the origin and return its normal and penetration as mentioned previously [8].

2.3 Collision Resolution

 In order to fully implement a collision response in our engine, we decided to implement a two part system to handle collisions. The first part of the system is an adaptation of the projection method. This is the part of the resolution that will handle the overlapping of physical objects and gives the shapes a solidity. Using the collision information generated by the GJK and EPA methods, we are able to separate out the colliding objects. This is done by adjusting the position of the colliding objects in opposite directions along the collision normal. This distance that the objects are moved is proportional to the penetration distance of the two physical objects and the mass of the object. Using the inverse mass of each object and dividing by the total mass of both colliding objects, a “heavier” object will move relatively less than a lighter one would. This results in a lessening of the amount of objects that will appear to be inside of something that it collides with. 

The second part of response is where we implement the change in inertia for both objects. Calculations for the impulse usually include an angular component, but that was excluded. Using the mass, velocities and positions of the two colliding objects, a contact velocity for the two objects is calculated. A float “j” is generated to represent the impulse, and using the total mass, linear parts of the impulse, and a coefficient of restitution we are able to calculate the full impulse that is to be acted on the objects. The first of the two objects receives a negative version of the impulse while the second receives the calculated value. This force is then added to each physical object, which will be used in the update while calculating new positions and velocities.[4]

2.4 Mouse Picking and Object Dragging

The last component of this project is the ability for the user to grab onto and drag objects within the scene. This implementation would allow you to test the capabilities of our collision system, as you would see the cause and effect of your actions in real time. In order to achieve this functionality, the screen coordinates must undergo a series of matrix inversions and multiplications. This operation begins by projecting firstly to the normalized device space, then to the eye space, and finally, to the world space. In addition, before reaching to world coordinates, we must intersect the coordinates obtained from our mouse cursor and find its intersection point with the objects currently underlying the cursor, from within the eye space. From here onwards, we can update the object's position with the resulting world coordinates.

With all that being said, a question arises: how do specific objects know when to reposition according to the mouse position? The answer is less mathematically-based as previous component implementations and relies more on an adept understanding of OpenGL architecture. The procedure is as follows: we calculate a unique color and assign it to each object within the scene. After, we send those colors as uniform variables so that they can be accessed in the fragment shader and reflected visually. We then use the OpenGL function, glReadPixels, to read the pixel data at the mouse coordinate and identify whether or not a match was made with one of the objects. As a result, objects can be selected and dragged according to the mouse position.

3.0 Difficulties & what could have been

Implementing a physics engine was a great learning experience as we’ve come to appreciate libraries and other physics engines that handle complex computation for us already. When it came to collision detection, generating contact points was the most complex aspect to calculate. We also hard coded the constraints of boxes hitting the floor. We managed to perform collision detection between the objects as if they were spheres since that is the most simple case. However, a correct implementation of collision detection would take into consideration the shape of the object in collision as well as the type of collision detected i.e. vertex-face collision, edge-edge collision, edge-face collision, etc [3]. Furthermore, the penetration depth value given from the EPA function was returning a very large number causing incorrect collision resolution, thus we had to resort to another method of calculating penetration depth as a way of solving this issue.

Implementing rotations and angular components to the physical objects would have a great boon for the engine. As it stands, each physical object only holds a linear aspect for their velocity. A full physics implementation would have kept track of the orientation and rotation of the object, by storing the angular velocities and a system to implement those changes on the object in question. If this had been achieved, once the applied impulse stage would begin, the impulse would not only have a linear aspect, but an angular one that would rotate objects based on forces imparted and location of the collision [6]. Unfortunately, angular aspects were attempted late into the development cycle and in the future, the classes and implementation would need to be built around angular inclusion. 

For a true engine product to be delivered, a full user interface would be preferred. Something that could place and select multiple objects, with editable parameters in the program, such as mass, elasticity or gravity. 

4.0 Conclusion

There are a lot of aspects that need to be considered when implementing a physics engine. Collision detection, collision response and rotations all need to be planned out carefully as one of these components can create issues if done poorly. After attempting to create an engine, the value of having already implemented libraries for physics, such as Bullet, cannot be overstated. Although we were not able to fully implement every aspect of the physics engine as was mentioned in the proposal, this project has been a valuable experience to understanding what goes on behind the scenes in any simulation or video game. 












5.0 Bibliography

[1]	Christer, Ericson. “Real-Time Collision Detection”. CRC Press, 2004. Inc., USA. 
[2]	Gerdelan, Anton. “Mouse Picking With Ray Casting”, 2 Oct. 2016.				 	https://antongerdelan.net/opengl/raycasting.html
[3]	Millington, Ian. “Game Physics Engine Development”. 2nd ed. CRC Press, 2010. Web. 		   14        Oct. 2022.
[4]	Morgan, Graham. “Game Engineering .” Physics Tutorials; Game Engineering; 			Newcastle University, 2018,								 		https://research.ncl.ac.uk/game/mastersdegree/gametechnologies/physicstutorials/.
[5]	Souto, Nilson. “Video Game Physics Tutorial - Part I: An Introduction to Rigid Body Dynamics.” Toptal Engineering Blog, Toptal, 22 Jan. 2015,					 https://www.toptal.com/game/video-game-physics-part-i-an-introduction-to-rigid-body-dynamics.
[6]	Souto, Nilson. “Video Game Physics Tutorial - Part II: Collision Detection for Solid	 Objects.” Toptal Engineering Blog, Toptal, 2 Mar. 2015,					 https://www.toptal.com/game/video-game-physics-part-ii-collision-detection-for-solid-objects.
[7]	WinterDev. “GJK Collision Detection Algorithm in 2D/3D”. 2020.	 				https://blog.winter.dev/2020/gjk-algorithm/
[8]	WinterDev. “EPA: Collision Response Algorithm for 2D/3D”. 2020.					 https://blog.winter.dev/2020/epa-algorithm/

http://www.opengl-tutorial.org/miscellaneous/clicking-on-objects/picking-with-an-opengl-hack/



